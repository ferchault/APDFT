{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning the alchemical potential for single elements\n",
    "The alchemical potential distribution is very narrow (similar to distribution of atomisation energy of the full molecules, see analysis_atomic_properties.ipynb). Wide range of labels can be excluded as limiting factor $\\rightarrow$ investigation of learning of $\\mu_I$ can improve understanding of limiting factors.\n",
    "\n",
    "## In this notebook\n",
    "- learning curve of alchemical potential of only hydrogen\n",
    "- learning curve of alchemical potential of all elements together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "from matplotlib import cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from scipy import stats\n",
    "\n",
    "def load_obj(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpots = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_all_alchpots.txt')\n",
    "all_alchpots_b2 = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_all_alchpots_b2.txt')\n",
    "all_alchpots_shifted = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_all_alchpots_shifted.txt')\n",
    "\n",
    "alchpots_H = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_H.txt')\n",
    "alchpots_H_b2 = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_H_b2.txt')\n",
    "\n",
    "alchpots_C = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_C.txt')\n",
    "alchpots_N = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_N.txt')\n",
    "alchpots_O = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_O.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [all_alchpots,all_alchpots_b2, \n",
    "            #all_alchpots_shifted, \n",
    "            alchpots_H, alchpots_H_b2, alchpots_C, alchpots_N, alchpots_O]\n",
    "labels = [r'all $\\mu$', r'all $\\mu$ batch 2',\n",
    "          #r'all $\\mu$ shifted', \n",
    "          r'$\\mu_{\\rm{H}}$', r'$\\mu_{\\rm{H}}$ batch 2', r'$\\mu_{\\rm{C}}$', r'$\\mu_{\\rm{N}}$', r'$\\mu_{\\rm{O}}$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# plt.rcParams.update({'errorbar.capsize': 0})\n",
    "\n",
    "for d,l in zip(datasets, labels):\n",
    "    if l == r'all $\\mu$':\n",
    "        ax.errorbar(d[:,0], d[:,1], d[:,2], label=l, color = \"tab:grey\")\n",
    "    else:\n",
    "        ax.errorbar(d[:,0], d[:,1], d[:,2], label=l)\n",
    "\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "directory = ('/home/misa/projects/Atomic-Energies/figures/machine_learning/learning_curves/')\n",
    "# plt.savefig(directory+'alchpots_split_up.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### together with learning curve of molecular atomisation energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurve_ref = np.loadtxt('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/reference/l_curve_global_global.tab')\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# plt.rcParams.update({'errorbar.capsize': 0})\n",
    "\n",
    "for d,l in zip(datasets, labels):\n",
    "    if l == r'all $\\mu$':\n",
    "        ax.errorbar(d[:,0], d[:,1], d[:,2], label=l, color = \"tab:grey\")\n",
    "    else:\n",
    "        ax.errorbar(d[:,0], d[:,1], d[:,2], label=l)\n",
    "\n",
    "ax.errorbar(lcurve_ref[:,0], lcurve_ref[:,1], lcurve_ref[:,2], label = r'$E^{\\rm{at, mol}}$')\n",
    "\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel('MAE (Ha)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "directory = ('/home/misa/projects/Atomic-Energies/figures/machine_learning/learning_curves/')\n",
    "plt.savefig(directory+'alchpots_split_up_with_ref.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### slopes of the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_ref=stats.linregress(np.log(lcurve_ref[:,0]), np.log(lcurve_ref[:,1]))\n",
    "fit_all=stats.linregress(np.log(all_alchpots[:,0]), np.log(all_alchpots[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(all_alchpots[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fit(x,fit):\n",
    "    return(fit[0]*x+fit[1])\n",
    "\n",
    "evaluate_fit(np.log(all_alchpots[:,0]), fit_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.log(lcurve_ref[:,0]),fit[0]*np.log(lcurve_ref[:,0])+fit[1])\n",
    "# plt.plot(np.log(lcurve_ref[:,0]), np.log(lcurve_ref[:,1]))\n",
    "labels = [r'all $\\mu$', \n",
    "          #r'all $\\mu$ shifted', \n",
    "          r'$\\mu_{\\rm{H}}$', r'$\\mu_{\\rm{C}}$', r'$\\mu_{\\rm{N}}$', r'$\\mu_{\\rm{O}}$',r'$E^{\\rm{at, mol}}$',r'all $\\mu$ last']\n",
    "\n",
    "for i,l in zip([all_alchpots, alchpots_H[7:], alchpots_C[4:], alchpots_N[4:], alchpots_O[4:], lcurve_ref, all_alchpots[9:]],labels):\n",
    "    x = np.log(i[:,0])\n",
    "    y = np.log(i[:,1])\n",
    "    fit = stats.linregress(x,y)\n",
    "    y_fitted = evaluate_fit(x, fit)\n",
    "    \n",
    "#     plt.plot(x,y)\n",
    "    if l == r'all $\\mu$':\n",
    "        plt.plot(x, y_fitted, label = l, color = 'tab:grey')\n",
    "    else:\n",
    "        plt.plot(x, y_fitted, label = l)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sigma_all_lam_alchpots_{el_symbol}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alchpot_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/cm/all_sigma_all_lam_alchpots_H.txt')\n",
    "lcurves = all_alchpot_dict\n",
    "# alchpot_H_dict = load_obj('/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/all_sigma_alchpots_O.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcurves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = 4#len(lcurves.keys())\n",
    "jet = cm = plt.get_cmap('jet') \n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.rcParams['figure.figsize'] = [10.0, 10.0]\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(NUM_COLORS)])\n",
    "for k in lcurves.keys():\n",
    "    if k.startswith('sig_103.96830673359823_'):\n",
    "        # r'$\\sigma = {}$'.format(np.round( float(k.split('_')[1]), 2 ))\n",
    "        ax.plot(lcurves[k][:,0], lcurves[k][:,1], '-o', label=k )\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(lcurves['sig_222.8609442038079'][:,0],lcurves['sig_222.8609442038079'][:,1], '-o', label=r'$\\sigma = 222$')\n",
    "ax.plot(lcurves['sig_103.96830673359823'][:,0],lcurves['sig_103.96830673359823'][:,1], '-o', label=r'$\\sigma = 104$')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum error for training set size of 2048 atoms = 0.012 Ha = 8 kcal/mol\n",
    "\n",
    "Error in atomisation energy for QM7 molecules with 5000 training points = 5 kcal/mol and 8.5 kcal/mol for 2048 training points (and 5000 test points)\n",
    "\n",
    "The errors are similar (check distribution of QM7 molecules to make sure they are also comparable)\n",
    "suggests, that noise in data is not an issue but spread (shift and rescale)\n",
    "\n",
    "compare to learning curve of 38Ve molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = qmi.generate_atomic_representations(data, molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.concatenate((np.logspace(0, 13, 14, base=2).astype(int), np.array([12000])))\n",
    "\n",
    "for sigma in sigmas:\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = crossvalidate(all_local_reps, alch_pots, tr_size, sigma, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_all_alchpots_b2.txt'\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/all_sigma_all_alchpots_b2.txt'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = qmi.generate_atomic_representations(data, molecule_size)\n",
    "\n",
    "# shift alchemical potentials by mean value per element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "mean_alch_pots = qmi.get_average_property(np.arange(molecule_size.sum()), data, molecule_size, 'alch_pot')\n",
    "\n",
    "delta_values = np.zeros((len(alch_pots)))\n",
    "for k in idc_by_charge.keys():\n",
    "    delta_values[idc_by_charge[k]] = mean_alch_pots[k]\n",
    "labels_shifted = (alch_pots - delta_values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that shift succesful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 10\n",
    "\n",
    "lcurves = dict()\n",
    "\n",
    "# define number of training points for which MAE is calculated\n",
    "set_sizes = np.logspace(0, 11, 12, base=2).astype(int)\n",
    "\n",
    "for sigma in sigmas:\n",
    "    error_cv = []\n",
    "    error_std = []\n",
    "    # calculate error for every training point size\n",
    "    for idx, tr_size in enumerate(set_sizes):\n",
    "        err, err_std = crossvalidate(all_local_reps, labels_shifted, tr_size, sigma, lam_val, num_cv)\n",
    "        error_cv.append(err)\n",
    "        error_std.append(err_std)\n",
    "    \n",
    "    lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best learning curve\n",
    "lowest_error = (None, None)\n",
    "for k in lcurves.keys():\n",
    "    if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "        lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "# filename\n",
    "path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_all_alchpots_shifted.txt'\n",
    "\n",
    "sig_val = lowest_error[0].split('_')[1]\n",
    "header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "# save dictionary of learning curves at all sigmas\n",
    "fname = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/all_sigma_all_alchpots_shifted.txt'\n",
    "save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    elif int(Z) == 9:\n",
    "        return('F')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "\n",
    "paths = qmi.wrapper_alch_data()\n",
    "# exclude only molecule with fluor\n",
    "exclude='/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_000829/atomic_energies_with_mic.txt'\n",
    "paths.remove(exclude)\n",
    "data, molecule_size = qmi.load_alchemy_data(paths)\n",
    "\n",
    "all_local_reps = qmi.generate_atomic_representations(data, molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecule_size[0:89].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for alchpots from pyscf or cpmd at lambda = 1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "#alch_pots = qmi.alchpot_lam1('pyscf')\n",
    "alch_pots = qmi.alchpot_lam1('cpmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_reps =dict()\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_reps[k] = all_local_reps[idc_by_charge[k]]\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    4    8   16   32   64  128  256  512 1024 2048 4096 5721]\n",
      "[   1    2    4    8   16   32   64  128  256  512 1024 2048 4096 4148]\n",
      "[   1    2    4    8   16   32   64  128  256  512 1024 1059]\n",
      "[  1   2   4   8  16  32  64 128 256 512 870]\n"
     ]
    }
   ],
   "source": [
    "sigmas = np.logspace(-1, 10, 11, base=2)\n",
    "lam_val = 1e-5\n",
    "num_cv = 3\n",
    "\n",
    "for charge in el_reps.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = np.concatenate((get_tr_size(len(el_alch_pots[charge])), np.array([int(len(el_alch_pots[charge])*0.9)])) )\n",
    "    print(set_sizes)\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        error_cv = []\n",
    "        error_std = []\n",
    "        # calculate error for every training point size\n",
    "        for idx, tr_size in enumerate(set_sizes):\n",
    "            err, err_std = crossvalidate(el_reps[charge], el_alch_pots[charge], tr_size, sigma, lam_val, num_cv)\n",
    "            error_cv.append(err)\n",
    "            error_std.append(err_std)\n",
    "\n",
    "        lcurves[f'sig_{sigma}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "    # save best learning curve\n",
    "    lowest_error = (None, None)\n",
    "    for k in lcurves.keys():\n",
    "        if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "            lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "    save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "    #path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/cm/best_sigma_alchpots_{el_symbol}.txt'\n",
    "    path = f'/home/misa/projects/Atomic-Energies/data/lcurves/lcurves_alch_pot/only_lambda1/alchpots_{el_symbol}_cpmd.txt'\n",
    "\n",
    "    sig_val = lowest_error[0].split('_')[1]\n",
    "    header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "    np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    #fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/cm/all_sigma_all_alchpots_{el_symbol}.txt'\n",
    "    fname = f'/home/misa/projects/Atomic-Energies/data/lcurves/lcurves_alch_pot/only_lambda1/all_sigma_alchpots_{el_symbol}_cpmd.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the error is higher than for atomic energies (check for bugs, overwritten variables...)\n",
    "\n",
    "$\\rightarrow$ rescaling and shifting is probably not the issue\n",
    "\n",
    "the surface is non smooth, rescaling does not help makes it even more non smooth\n",
    "\n",
    "$\\rightarrow$ change of representation could help\n",
    "\n",
    "- also learning only H is easier (maybe smoother)\n",
    "$\\rightarrow$ learn all elements individually\n",
    "\n",
    "what is the optimal representation? \n",
    "$\\rightarrow$  investigate label distribution, distance distribution (for all together/single element)\n",
    "\n",
    "deep neural networks are supposed to work better for non smooth systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for alchemical potential of single elements optimize $\\sigma$ and $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qml\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/git_repositories/APDFT/prototyping/atomic_energies/')\n",
    "import qml_interface as qmi\n",
    "import sklearn.model_selection as sk\n",
    "import pickle\n",
    "\n",
    "def crossvalidate(reps, labels, tr_size, sigma, lam, num_cv):\n",
    "    errors = []\n",
    "    for cv in range(num_cv):\n",
    "        reps_tr, reps_test, labels_tr, labels_test = sk.train_test_split(reps,labels,train_size=tr_size)\n",
    "        coeffs = qmi.train_kernel(reps_tr, labels_tr, sigma, lam_val)\n",
    "        labels_predicted = qmi.predict_labels(reps_test, reps_tr, sigma, coeffs)\n",
    "        errors.append((np.abs(labels_predicted - labels_test)).mean())\n",
    "    errors = np.array(errors)\n",
    "    return(errors.mean(), errors.std())\n",
    "\n",
    "def save_obj(obj, fname ):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_tr_size(data_size):\n",
    "    \"\"\"\n",
    "    largest number of training points is roughly 90% of complete data (largest multiple of 2 that is <= 90%)\n",
    "    \"\"\"\n",
    "    largest_set = int(np.log2(data_size*0.9))\n",
    "    tr_size = np.logspace(0, largest_set, largest_set+1, base=2).astype(int)\n",
    "    return(tr_size)\n",
    "\n",
    "def get_element_symbol(Z):\n",
    "    if int(Z) == 1:\n",
    "        return('H')\n",
    "    elif int(Z) == 6:\n",
    "        return('C')\n",
    "    elif int(Z) == 7:\n",
    "        return('N')\n",
    "    elif int(Z) == 8:\n",
    "        return('O')\n",
    "    else:\n",
    "        raise ValueError('Symbol for given charge not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, molecule_size = qmi.load_alchemy_data(qmi.wrapper_alch_data())\n",
    "alch_pots = qmi.generate_label_vector(data, molecule_size.sum(), value='alch_pot')\n",
    "\n",
    "all_local_reps = qmi.generate_atomic_representations(data, molecule_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up alchemical potential by element\n",
    "charges = qmi.generate_label_vector(data, molecule_size.sum(), value='charge')\n",
    "idc_by_charge = qmi.partition_idx_by_charge(charges)\n",
    "\n",
    "el_reps =dict()\n",
    "el_alch_pots = dict()\n",
    "for k in idc_by_charge.keys():\n",
    "    el_reps[k] = all_local_reps[idc_by_charge[k]]\n",
    "    el_alch_pots[k] = alch_pots[idc_by_charge[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best sigmas\n",
    "sigmas = np.logspace(-1, 10, 11, base=2)[6:11]\n",
    "lam_vals = [1e-3, 1e-5, 1e-7, 1e-9]\n",
    "num_cv = 10\n",
    "\n",
    "for charge in el_reps.keys():\n",
    "    lcurves = dict()\n",
    "\n",
    "    # define number of training points for which MAE is calculated\n",
    "    set_sizes = get_tr_size(len(el_alch_pots[charge]))\n",
    "    \n",
    "    # special for H\n",
    "#     set_sizes = np.concatenate((set_sizes, np.array([3300])))\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        for lam_val in lam_vals:\n",
    "            error_cv = []\n",
    "            error_std = []\n",
    "            # calculate error for every training point size\n",
    "            for idx, tr_size in enumerate(set_sizes):\n",
    "                err, err_std = crossvalidate(el_reps[charge], el_alch_pots[charge], tr_size, sigma, lam_val, num_cv)\n",
    "                error_cv.append(err)\n",
    "                error_std.append(err_std)\n",
    "\n",
    "            lcurves[f'sig_{sigma}_lam{lam_val}'] = np.array([set_sizes, error_cv, error_std]).T\n",
    "        \n",
    "    \n",
    "#     # save best learning curve\n",
    "#     lowest_error = (None, None)\n",
    "#     for k in lcurves.keys():\n",
    "#         if lowest_error[1]==None or lowest_error[1] > np.amin(lcurves[k][:,1]):\n",
    "#             lowest_error = (k, np.amin(lcurves[k][:,1]))\n",
    "#     save_data = lcurves[lowest_error[0]]\n",
    "\n",
    "    # filename\n",
    "    el_symbol = get_element_symbol(charge)\n",
    "#     path = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/best_alchpots_{el_symbol}.txt'\n",
    "\n",
    "#     sig_val = lowest_error[0].split('_')[1]\n",
    "#     header = f'sigma = {sig_val}, lambda = {lam_val}, number cv = {num_cv}'\n",
    "#     np.savetxt(path, save_data, delimiter='\\t', header=header)\n",
    "\n",
    "    # save dictionary of learning curves at all sigmas\n",
    "    fname = f'/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/lcurves_alch_pot/cm/all_sigma_all_lam_alchpots_{el_symbol}.txt'\n",
    "    save_obj(lcurves, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
