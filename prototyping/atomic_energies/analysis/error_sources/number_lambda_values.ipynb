{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of $\\lambda$-values\n",
    "The number and distribution of $\\lambda$-values influences the error in the calculation of atomic energies. This notebook investigates how the much the ML-error changes if \n",
    "- the number of $\\lambda$-values is changed (adding/removing densities at certain $\\lambda$-values)\n",
    "\n",
    "The code for the generation of the data can be found in:\n",
    "\n",
    "alchemy_tools.test_impact_lambda: calculates the atomic energies where always one $\\lambda$-value (of 0.2, 0.4, 0.6, 0.8) is neglected. The data is stored in /home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/compound/no_*ve*.txt (where the neglected $\\lambda = \\frac{ve}{38}$\n",
    "\n",
    "crossvalidate.choose_different_lambdas: generates crossvalidated learning curves using the atomic energies created by test_impact_lambda; the hyperparameters are the same as for the data where all $\\lambda$-values are used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-Error if one $\\lambda$-value is left out\n",
    "The plot shows learning curves if one $\\lambda$-value is left out and the learning curve where all $\\lambda$-values are used. ~The error is for all curves in the same range which shows that an unsufficient number of $\\lambda$-values is not the main contributor to the error. (In principle using all $\\lambda$-values should give the lowest error, this is not for every training set size the case. The reason for this behaviour is probably, that the number of crossvalidation samples (=10) is not large enough).~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load learning curves\n",
    "\n",
    "base_path = '/home/misa/APDFT/prototyping/atomic_energies/results/analyse_learning/'\n",
    "l_curves_data = ['learning_curves.tab', 'no_8.tab', 'no_15.tab', 'no_23.tab', 'no_30.tab']\n",
    "\n",
    "l_curves = np.empty((5,10,3))\n",
    "\n",
    "for idx, lc in enumerate(l_curves_data):\n",
    "    l_curves[idx] = np.loadtxt(base_path+lc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "labels = ['all', 'no $\\lambda_{0.2}$', 'no $\\lambda_{0.4}$', 'no $\\lambda_{0.6}$', 'no $\\lambda_{0.8}$']\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "for idx, l in enumerate(labels):\n",
    "    ax.plot(l_curves[idx][:,0], l_curves[idx][:,1], '-o', label = l)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel('Training set size')\n",
    "ax.set_ylabel('Mean error  (Ha)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in atomisation energy if one $\\lambda$-value is left out\n",
    "The difference between the integrals where all $\\lambda$-values are used and where $\\lambda \\approx 0.8$ is left out is $\\approx 0.05$ Ha. This value is in the order of the minimum error that we obtain for our learning curves (0.02 Ha). This suggest, that the number of $\\lambda$-values is insufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/misa/APDFT/prototyping/atomic_energies')\n",
    "import qml_interface as qi\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_all = '/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/finished_abs'\n",
    "paths_all = qi.wrapper_alch_data(p_all)\n",
    "\n",
    "p_no30 = '/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/paths_no_30'\n",
    "paths_no30 = qi.wrapper_alch_data(p_no30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that same order\n",
    "a=[el.rstrip('no_30.txt') for el in paths_no30]\n",
    "b=[el.rstrip('atomic_energies.txt') for el in paths_all]\n",
    "\n",
    "for idx in range(len(a)):\n",
    "    assert a[idx]==b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all, msize_all = qi.load_alchemy_data(paths_all)\n",
    "data_no_30, msize_no30 = qi.load_alchemy_data(paths_no30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for idx in range(len(data_all)):\n",
    "    diff.extend(data_all[idx][:,5] - data_no_30[idx][:,5])\n",
    "diff = np.array(diff)\n",
    "mean_diff = np.abs(diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "mean=[]\n",
    "std = []\n",
    "idx_per_charge = qi.partition_idx_by_charge(data_all, range(len(data_all)))\n",
    "for i in range(len(idx_per_charge)):\n",
    "    ax[0].scatter(range(len(idx_per_charge[i][1][0])),diff[idx_per_charge[i][1]], label = 'Z = {}'.format(idx_per_charge[i][0]))\n",
    "#     ax[1].bar(i, np.abs(diff[idx_per_charge[i][1]]).mean()  )\n",
    "    mean.append(np.abs(diff[idx_per_charge[i][1]]).mean())\n",
    "    std.append(np.abs(diff[idx_per_charge[i][1]]).std())\n",
    "    \n",
    "ax[0].set_xlabel('atom ID')\n",
    "ax[0].set_ylabel(r'$\\Delta E_{atomic}$ (Ha)')\n",
    "ax[0].legend()\n",
    "\n",
    "mean.append(np.abs(diff).mean())\n",
    "std.append(np.abs(diff).std())\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "ax[1].bar(range(len(idx_per_charge)+1),mean, yerr=std, tick_label=['Z = 1', 'Z = 6', 'Z = 7', 'Z = 8', 'all'], color = colors[0:len(idx_per_charge)+1])\n",
    "ax[1].set_ylabel(r'$\\overline{\\Delta E}_{atomic}$ (Ha)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of the integral $\\int d\\lambda$\n",
    "We calculate the integral for different amounts of $\\lambda$-values and plot how the integral changes if more values are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/misa/APDFT/prototyping/atomic_energies')\n",
    "\n",
    "import alchemy_tools as at\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(directory):\n",
    "    # load data from cube files\n",
    "    paths_cubes = ['/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/ueg/ve_00.cube']\n",
    "    paths2 = glob.glob(directory+'/cube-files/*')\n",
    "    paths2.sort()\n",
    "    paths_cubes.extend(paths2)\n",
    "    return(paths_cubes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta E_{atomic} = E(\\text{the original 6}) - E(\\text{all} \\lambda)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_003712',\n",
    " '/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_003886',\n",
    " '/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_001212']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_en = []\n",
    "diff_alch = []\n",
    "\n",
    "for d in directories:\n",
    "    paths_cubes = get_paths(d)\n",
    "    # all lambda values\n",
    "    lam_vals, densities, nuclei, gpts = at.load_cube_data(paths_cubes)\n",
    "    av_dens = at.integrate_lambda_density(densities, lam_vals, method='trapz')\n",
    "    atomic_energies, alch_pots = at.calculate_atomic_energies(av_dens, nuclei, gpts)\n",
    "    \n",
    "    # the orginal 6\n",
    "    old_densities = []\n",
    "    old_lam_vals = []\n",
    "\n",
    "    for i in range(len(lam_vals)):\n",
    "        if lam_vals[i] in [0, 8/38, 15/38, 23/38, 30/38, 38/38]:\n",
    "            old_lam_vals.append(lam_vals[i])\n",
    "            old_densities.append(densities[i])\n",
    "            \n",
    "    av_dens_old = at.integrate_lambda_density(old_densities, old_lam_vals, method='trapz')\n",
    "    atomic_energies_old, alch_pots_old = at.calculate_atomic_energies(av_dens_old, nuclei, gpts)\n",
    "    \n",
    "    diff_en.append(atomic_energies_old-atomic_energies)\n",
    "    diff_alch.append(alch_pots_old - alch_pots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(np.abs(diff_en[i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_alch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(np.abs(diff_alch[i]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\frac{d}{d \\lambda} \\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivatives(lam_vals, densities):\n",
    "    derivatives = []\n",
    "    for idx in range(1, len(densities)):\n",
    "        d_dens_lam = (densities[idx] - densities[idx-1])/(lam_vals[idx]-lam_vals[idx-1])\n",
    "        derivatives.append(d_dens_lam)\n",
    "    \n",
    "    derivatives = np.array(derivatives)\n",
    "    return(derivatives)\n",
    "\n",
    "def sum_gradients(derivatives):\n",
    "    gradients = []\n",
    "    for idx in range(len(derivatives)):\n",
    "        sum_gradients = np.abs(derivatives[idx]).sum()\n",
    "        gradients.append(sum_gradients)\n",
    "    return(np.array(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = get_derivatives(lam_vals, densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_sum = sum_gradients(derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_derivatives = get_derivatives(old_lam_vals, old_densities)\n",
    "old_gradients_sum = sum_gradients(old_derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_gradients_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate importance of $\\lambda$-value for integral\n",
    "~The atomic energies are calculated by integrated over a finite amount of $\\lambda$-values.\n",
    "The integration error for an interval depends on the maximum gradient of the function in the interval.\n",
    "Thus, the maximum gradient is helpful to identify the minimum set of $\\lambda$-values, that yields atomic energies with an error below a certain threshold.\n",
    "We calculate the average gradient $\\bar{g}_{i, i-1}(\\vec{r}_j)$ between two $\\lambda$-points $\\lambda_i, \\lambda_{i-1}$ for all pairs of adjacent points at every gridpoint $\\vec{r}_j$ as~\n",
    "\n",
    "~\\begin{equation}\n",
    "\\bar{g}_{i, i-1}(\\vec{r}_j) = \\frac{\\rho(\\lambda_i, \\vec{r}_j) - \\rho(\\lambda_{i-1}, \\vec{r}_j) }{ \\lambda_{i} - \\lambda_{i-1} },\n",
    "\\end{equation}\n",
    "where $\\rho(\\lambda_i, \\vec{r}_j)$ is the density for $\\lambda_i$ at point $\\vec{r}_j$ in space.~\n",
    "\n",
    "~Therefore, we obtain a set of $M$ gradients $\\{\\bar{g}_{i, i-1}(\\vec{r}_j)\\}$, where $M$ is the number of gridpoints for $N-1$ pairs of adjacent $\\lambda$-values, where $N$ is the number of $\\lambda$-values.\n",
    "An estimate for the integration error $\\Delta I$ in case of trapezoidal integration is:\n",
    "\\begin{equation}\n",
    "    \\Delta I_{i, i-1}(\\vec{r}_j) \\propto f''_{i-1/2}(\\vec{r}_j)(\\lambda_{i} - \\lambda_{i-1})^3,\n",
    "\\end{equation}\n",
    "where $f''_{i-1/2}$ is the second derivative $\\frac{d^2f}{d \\lambda^2}$ at the midpoint between $\\lambda_{i}$ and $ \\lambda_{i-1} $. $f''_{i-1/2}$ can be approximated by\n",
    "\\begin{equation}\n",
    "f''_{i-1/2} \\approx \\frac{ f''_{i} + f''_{i-1}}{2}.\n",
    "\\end{equation}\n",
    "$ f''_{i} $ canbe calculated with the centratl difference scheme as\n",
    "\\begin{equation}\n",
    "    f''_{i} = \\frac{ f''_{i+1} - 2\\cdot f''_{i} + f''_{i-1} }{}\n",
    "\\end{equation}\n",
    "Then, we can estimate the error in alchemical potential $\\Delta \\mu$ at gridpoint $\\vec{r}_j$ as\n",
    "\\begin{equation}\n",
    "    \\Delta \\mu_{i, i-1, k} = \\int d\\vec{r} \\frac{\\Delta I_{i, i-1}(\\vec{r})}{|\\vec{r}-\\vec{R}_k|},\n",
    "\\end{equation}\n",
    "where $\\vec{R}_k$ is the position of nucleus $k$ and the error in atomic energies $ \\Delta \\Delta E_{i, i-1} $ is\n",
    "\\begin{equation}\n",
    "    \\Delta \\Delta E_{i, i-1} = \\sum_k Z_k \\Delta \\mu_{i, i-1, k},\n",
    "\\end{equation}\n",
    "where the $Z_k$ are the nuclear charges of the nuclei.~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate $\\Delta E'$ as \n",
    "\\begin{equation}\n",
    "    \\Delta E' = \\sum_I Z_I \\int d\\vec{r} \\int_0^{\\lambda'} d\\lambda \\frac{\\rho(\\lambda, \\vec{r})}{|\\vec{r}-\\vec{R}_I|}\n",
    "\\end{equation}\n",
    "\n",
    "and plot $\\Delta E'$ vs $\\lambda'$. These plots are constructed for two sets of $\\lambda$-values with different amounts of $\\lambda$-points. The difference between the curves $\\Delta E'$ for the sets could help to identify the intervals in which a high number of $\\lambda$-values is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/misa/APDFT/prototyping/atomic_energies')\n",
    "\n",
    "import alchemy_tools as at\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "def get_paths(directory):\n",
    "    # load data from cube files\n",
    "    paths_cubes = ['/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/ueg/ve_00.cube']\n",
    "    paths2 = glob.glob(directory+'/cube-files/*')\n",
    "    paths2.sort()\n",
    "    paths_cubes.extend(paths2)\n",
    "    return(paths_cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cube-files\n",
    "\n",
    "# for set choose adjacent densities and lam_vals and call integrate_lambda_density, calculate_atomic_energies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cube-files\n",
    "compound = 'dsgdb9nsd_001212'\n",
    "paths_cubes = get_paths('/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_001212')\n",
    "lam_vals, densities, nuclei, gpts = at.load_cube_data(paths_cubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate over six roughly evenly spaced points from 0 to 1 using the trapezoidal rule. I calculate the integral piecewise for every pair of adjacent points $a, b$.\n",
    "\\begin{equation}\n",
    "    I_{ab, coarse} = \\int_a^b d \\lambda \\rho(\\lambda)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of the six points on the coarse grid\n",
    "idx_set_small = []\n",
    "for idx, val in enumerate(lam_vals):\n",
    "    if val in [0, 8/38, 15/38, 23/38, 30/38, 1]:\n",
    "        idx_set_small.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trapezoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small set\n",
    "# energies\n",
    "e_prime = []\n",
    "lambda_prime = []\n",
    "\n",
    "for idx in range(0, 5):\n",
    "    a = idx_set_small[idx]\n",
    "    b = idx_set_small[idx+1]\n",
    "    lambda_prime.append(lam_vals[b])\n",
    "    av_dens = at.integrate_lambda_density([densities[a], densities[b]], [lam_vals[a], lam_vals[b]])\n",
    "    atomic_energies, alch_pots = at.calculate_atomic_energies(av_dens, nuclei, gpts)\n",
    "    e_prime.append(atomic_energies.sum())\n",
    "\n",
    "e_prime_small = np.array(e_prime)\n",
    "e_prime_cum_small = np.array(e_prime).cumsum()\n",
    "lambda_prime_small_cum = np.array(lambda_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_small.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lambda-vals and densities for small set of lambda points\n",
    "small_densities = []\n",
    "small_lam_vals = []\n",
    "\n",
    "for idx in idx_set_small:\n",
    "    small_densities.append(densities[idx])\n",
    "    small_lam_vals.append(lam_vals[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate csplines for small dataset\n",
    "shape = densities[0].shape\n",
    "reshaped_densities = at.reshape_densities(small_densities)\n",
    "poly_obj_small = scipy.interpolate.CubicSpline(small_lam_vals, reshaped_densities, axis=0, bc_type=('clamped', 'not-a-knot'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = np.array([0, 8, 15, 23, 30, 38])/38\n",
    "e_prime = []\n",
    "for idx in range(len(integration_bounds)-1):\n",
    "    averaged_density = poly_obj_small.integrate(integration_bounds[idx], integration_bounds[idx+1])\n",
    "    averaged_density = np.reshape(averaged_density, shape)\n",
    "    atomic_energies, alch_pots = at.calculate_atomic_energies(averaged_density, nuclei, gpts)\n",
    "    e_prime.append(atomic_energies.sum())\n",
    "    \n",
    "e_prime_small_csplines = np.array(e_prime)\n",
    "e_prime_cum_small_csplines = np.array(e_prime).cumsum()\n",
    "lambda_prime_small_cum_csplines = integration_bounds[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_small_csplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_cum_small_csplines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large grid\n",
    "Integrate over all points of the fine grid. Calculate the integrals piecewise between pairs of adjacent points\n",
    "\\begin{equation}\n",
    "I_{a'b'} = \\int_{a'}^{b'} d \\lambda \\rho^*(\\lambda)\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trapezoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large set\n",
    "# energies\n",
    "e_prime = []\n",
    "# even_idx = np.where(np.array(lam_vals)*38%2 == 0)[0]\n",
    "for idx in range(0, len(densities)-1):\n",
    "    a = idx\n",
    "    b = idx+1\n",
    "    av_dens = at.integrate_lambda_density([densities[a], densities[b]], [lam_vals[a], lam_vals[b]])\n",
    "    atomic_energies, alch_pots = at.calculate_atomic_energies(av_dens, nuclei, gpts)\n",
    "    e_prime.append(atomic_energies.sum())\n",
    "                        \n",
    "e_prime_full = np.array(e_prime) # stepwise energies\n",
    "e_prime_cum_full = np.array(e_prime).cumsum() # cumulated energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_full.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_cum_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains all lam vals except for lambda = 0\n",
    "lambda_prime = []\n",
    "for idx in range(0, len(lam_vals)-1):\n",
    "    a = idx\n",
    "    b = idx+1\n",
    "    lambda_prime.append(lam_vals[b])\n",
    "lambda_prime_full_cum = np.array(lambda_prime)\n",
    "lambda_prime_full_cum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate csplines for large dataset\n",
    "shape = densities[0].shape\n",
    "reshaped_densities = at.reshape_densities(densities)\n",
    "poly_obj_full = scipy.interpolate.CubicSpline(lam_vals, reshaped_densities, axis=0, bc_type=('clamped', 'not-a-knot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = np.array(lam_vals)\n",
    "e_prime = []\n",
    "for idx in range(len(integration_bounds)-1):\n",
    "    averaged_density = poly_obj_full.integrate(integration_bounds[idx], integration_bounds[idx+1])\n",
    "    averaged_density = np.reshape(averaged_density, shape)\n",
    "    atomic_energies, alch_pots = at.calculate_atomic_energies(averaged_density, nuclei, gpts)\n",
    "    e_prime.append(atomic_energies.sum())\n",
    "    \n",
    "e_prime_csplines = np.array(e_prime)\n",
    "e_prime_cum_csplines = np.array(e_prime).cumsum()\n",
    "lambda_prime_cum_csplines = integration_bounds[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_cum_csplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cspline stuff\n",
    "e_prime_small = e_prime_small_csplines\n",
    "e_prime_cum_small = e_prime_cum_small_csplines\n",
    "lambda_prime_small_cum = lambda_prime_small_cum_csplines\n",
    "\n",
    "e_prime_full = e_prime_csplines # stepwise energies\n",
    "e_prime_cum_full = np.array(e_prime_csplines).cumsum() # cumulated energies\n",
    "lambda_prime_full_cum = integration_bounds[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_cum_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference fine and coarse grid\n",
    "Compare the integrals over the fine grid and the coarse grid by comparing the integral values over the intervals $[a,b]$ of the coarse grid. For this comparison the integrals $I_{a'b'}$ over the fine grid must be summed up as \n",
    "\\begin{equation}\n",
    "I_{ab, fine} = \\sum_{a,b'}^{a', b} I_{a', b'}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrals of fine grid over same lambda values as for coarse grid\n",
    "delta_fine = []\n",
    "for idx in range(0, len(idx_set_small)-1):\n",
    "    a = lam_vals[idx_set_small[idx]] # point lower interval limit a on the coarse grid\n",
    "    b = lam_vals[idx_set_small[idx+1]] # upper interval limit on the coarse grid\n",
    "    \n",
    "    # lambda_prime_full_cum is the lambda value up to which is integrated from 0 if the cumulative \n",
    "    # energy is given (it contains all lambda values of the fine grid except for lambda = 0)\n",
    "    E_coarse = e_prime_full[np.where((lambda_prime_full_cum>a) & (lambda_prime_full_cum<=b) )].sum()\n",
    "    print(np.where((lambda_prime_full_cum>a) & (lambda_prime_full_cum<=b) ))\n",
    "    delta_fine.append(E_coarse)\n",
    "\n",
    "I_fine = np.array(delta_fine)\n",
    "I_fine.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the integrals over the interval $[a, b]$ is then\n",
    "\\begin{equation}\n",
    "    \\Delta I = I_{ab, fine} - I_{ab, coarse}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_I = I_fine - e_prime_small\n",
    "delta_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot - Difference over every interval $[a, b]$\n",
    "Bar plot of integrals over the intervals $[a, b]$ on the fine and the coarse grid and the difference between  those integrals\n",
    "- Shows difference of integrals over certain intervals\n",
    "- the intervals where the difference is largest need biggest amount of additional data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.suptitle(compound)\n",
    "\n",
    "tick_label = ['[0.0, 0.2]', '[0.2, 0.4]', '[0.4, 0.6]', '[0.6, 0.8]', '[0.8, 1.0]']\n",
    "ax[0].bar(np.arange(len(I_fine))+0.125, I_fine, width = 0.25, color='blue', alpha=0.3, tick_label = tick_label, label='fine grid')\n",
    "ax[0].bar(np.arange(len(I_fine))-0.125, e_prime_small, width = 0.25, color='red', alpha=0.3, tick_label = tick_label, label='coarse grid')\n",
    "ax[1].bar(np.arange(len(I_fine)), delta_I, width = 0.25, color='orange', alpha=0.3, tick_label = tick_label)\n",
    "\n",
    "# axis labels\n",
    "ax[0].set_xlabel('Integration interval')\n",
    "ax[0].set_ylabel(r'$E_{ab} =  \\int_a^b d \\lambda \\rho^*(\\lambda)$ [Ha]')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_xlabel('Integration interval')\n",
    "ax[1].set_ylabel(r'$E_{ab, fine} -E_{ab, coarse}$ [Ha]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot - Cumulated integrals\n",
    "The region where the curves has the stepest slope should be the region where the error is largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_title(compound)\n",
    "\n",
    "ax.plot(lambda_prime_full_cum, e_prime_cum_full, '-o', label='fine grid')\n",
    "ax.plot(lambda_prime_small_cum, e_prime_cum_small, '-o', label='coarse grid')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\Delta E = \\sum_I Z_I \\int_0^{\\lambda} d\\lambda \\rho_I*(\\lambda) $')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot - Increase over evenly spaced intervals\n",
    "For the fine grid the increase of the integral over $[a,b]$ is almost linear, while it is a lot more unsteady for the coarse grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prime_cum_small_csplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda values for cumulated integral\n",
    "lambda_prime = []\n",
    "even_idx = np.where(np.array(lam_vals)*38%2 == 0)[0]\n",
    "for idx in range(0, len(even_idx)):\n",
    "    a = even_idx[idx]\n",
    "    lambda_prime.append(lam_vals[a])\n",
    "lambda_even_large = np.array(lambda_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrals on fine grid over evenly spaced intervals\n",
    "I_even = []\n",
    "for idx in range(0, len(lambda_even_large)-1):\n",
    "    a = lambda_even_large[idx] \n",
    "    b = lambda_even_large[idx+1] \n",
    "    \n",
    "    E_coarse = e_prime_full[np.where((lambda_prime_full_cum>a) & (lambda_prime_full_cum<=b) )].sum()\n",
    "\n",
    "    I_even.append(E_coarse)\n",
    "\n",
    "I_even = np.array(I_even)\n",
    "I_even.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value of integrals and difference between coarse and fine grid\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_title(compound)\n",
    "ax.plot(lambda_even_large[1:], I_even, '-o', label = 'fine grid')\n",
    "ax.plot(lambda_prime_small_cum, e_prime_small, '-o', label = 'coarse grid')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$b$')\n",
    "ax.set_ylabel(r'$\\Delta E = \\sum_I Z_I \\int_a^{b} d\\lambda \\rho_I*(\\lambda) $')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example plot for projected densities at different $\\lambda$-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "sys.path.insert(0, '/home/misa/APDFT/prototyping/atomic_energies')\n",
    "from parse_cube_files import CUBE\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1)\n",
    "a.plot(np.arange(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/misa/APDFT/prototyping/atomic_energies/results/slice_ve38/dsgdb9nsd_001212/cube-files'\n",
    "paths = glob.glob(p+'/*.cube')\n",
    "paths.sort()\n",
    "\n",
    "cubes = []\n",
    "for path in paths:\n",
    "    cubes.append(CUBE(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(paths[0].split('/')[-1].split('.')[0].split('_')[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomic-energies]",
   "language": "python",
   "name": "conda-env-atomic-energies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
